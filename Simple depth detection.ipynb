{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "# Load the MiDaS model\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_large\")\n",
    "midas.eval()\n",
    "\n",
    "# Load the MiDaS transforms\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").small_transform \n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "midas.to(device)\n",
    "\n",
    "# Estimating Depth Fn\n",
    "def estimate_depth(frame):\n",
    "    input_batch = midas_transforms(frame).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "        depth_map = prediction.squeeze().cpu().numpy()\n",
    "        return depth_map \n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "\n",
    "    # Resize the input image to match the model input \n",
    "    input_frame = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (256,256))\n",
    "\n",
    "    # Estimate depth\n",
    "    depth_map = estimate_depth(input_frame)\n",
    "\n",
    "    # Normalize the depth map for visualization\n",
    "    depth_map_normalize = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    depth_map_colored = cv2.applyColorMap(depth_map_normalize, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Display both the original frame and depth map\n",
    "    combined = np.hstack((frame, cv2.resize(depth_map_colored,(frame.shape[1], frame.shape[0]))))\n",
    "    cv2.imshow(\"Depth Detection\", combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
